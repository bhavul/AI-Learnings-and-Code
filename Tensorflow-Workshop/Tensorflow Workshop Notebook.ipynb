{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape is something you can get w/o running computation. But Rank you get after running the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = tf.Variable(987, tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a property of a tensor\n",
    "scalar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar has 0 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank you can only get after running. Not a property. \n",
    "sess = tf.Session()\n",
    "rank = tf.rank(scalar)\n",
    "sess.run(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector = tf.Variable([1,2], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = tf.Variable([[1,2],[3,4]], tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess2 = tf.Session()\n",
    "rank2 = tf.rank(vector)\n",
    "sess2.run(rank2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess3 = tf.Session()\n",
    "rank3 = tf.rank(matrix)\n",
    "sess3.run(rank3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tensor = tf.Variable([[[1,2],[3,4]],[[1,2],[3,4]]], tf.int16\n",
    "                      )\n",
    "sess4 = tf.Session()\n",
    "rank4 = tf.rank(matrix)\n",
    "sess4.run(rank4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex1.py - Advertising Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230.1, 44.5, 17.2, 151.5, 180.8, 8.7, 57.5, 120.2, 8.6, 199.8, 66.1, 214.7, 23.8, 97.5, 204.1, 195.4, 67.8, 281.4, 69.2, 147.3, 218.4, 237.4, 13.2, 228.3, 62.3, 262.9, 142.9, 240.1, 248.8, 70.6, 292.9, 112.9, 97.2, 265.6, 95.7, 290.7, 266.9, 74.7, 43.1, 228.0, 202.5, 177.0, 293.6, 206.9, 25.1, 175.1, 89.7, 239.9, 227.2, 66.9, 199.8, 100.4, 216.4, 182.6, 262.7, 198.9, 7.3, 136.2, 210.8, 210.7, 53.5, 261.3, 239.3, 102.7, 131.1, 69.0, 31.5, 139.3, 237.4, 216.8, 199.1, 109.8, 26.8, 129.4, 213.4, 16.9, 27.5, 120.5, 5.4, 116.0, 76.4, 239.8, 75.3, 68.4, 213.5, 193.2, 76.3, 110.7, 88.3, 109.8, 134.3, 28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7, 135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9, 25.0, 90.4, 13.1, 255.4, 225.8, 241.7, 175.7, 209.6, 78.2, 75.1, 139.2, 76.4, 125.7, 19.4, 141.3, 18.8, 224.0, 123.1, 229.5, 87.2, 7.8, 80.2, 220.3, 59.6, 0.7, 265.2, 8.4, 219.8, 36.9, 48.3, 25.6, 273.7, 43.0, 184.9, 73.4, 193.7, 220.5, 104.6, 96.2, 140.3, 240.1, 243.2, 38.0, 44.7, 280.7, 121.0, 197.6, 171.3, 187.8, 4.1, 93.9, 149.8, 11.7, 131.7, 172.5, 85.7, 188.4, 163.5, 117.2, 234.5, 17.9, 206.8, 215.4, 284.3, 50.0, 164.5, 19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6, 156.6, 218.5, 56.2, 287.6, 253.8, 205.0, 139.5, 191.1, 286.0, 18.7, 39.5, 75.5, 17.2, 166.8, 149.7, 38.2, 94.2, 177.0, 283.6, 232.1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read csv file\n",
    "adv = pd.read_csv('Advertising.csv')\n",
    "\n",
    "# extract TV column\n",
    "tv_budget_x = adv.TV.tolist()\n",
    "\n",
    "# print array\n",
    "print(tv_budget_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to a tensor\n",
    "\n",
    "* Go here - https://www.tensorflow.org/api_docs/\n",
    "* expand tf, you'll find convert_to_tensor\n",
    "* Let's try to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you look at docs, only first arg is mandatory, rest can take None.\n",
    "x_tensor = tf.convert_to_tensor(tv_budget_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this tensor printing won't print any of its values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(200,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find mean of the array\n",
    "Remember, array is also a tensor\n",
    "Same, go to the docs. You'll find reduce_mean - https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor\n",
    "\n",
    "If you check it, this one takes an ***input_tensor***. It is not like the convert_to_tensor which just took a ***value***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_mean = tf.reduce_mean(x_tensor)\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Sum Operation\n",
    "\n",
    "Say you have a matrix [[1,1,1], [1,1,1]]\n",
    "It's a 2 dimensional thing. An array of 2 arrays. \n",
    "If you reduce it along ***AXIS 0*** then it'll give you [2,2,2]\n",
    "If you reduce it along ***Axis 1*** then it'll give you [3,3]\n",
    "If you keep ***keep_dims=True***, then you do get sum, but dimensions are same - [[3],[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,1,1],[1,1,1]]\n",
    "tf.reduce_sum(x,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Why don't we see values\n",
    "Dude, tensor does not exist on its own. We need the graph to run them and see its values. We can only see info about it like its shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "* Builds the graph\n",
    "* Execute the graph\n",
    "* Converts to C++ runtime code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing value of a tensor\n",
    "Let's run the graph.\n",
    "**Notice how the same command (print) without a session gives us info of a tensor, and inside session gives us the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(200,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# the same advertising TV data \n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Advertising Data for TV-------\n",
      "[ 230.1000061    44.5          17.20000076  151.5         180.80000305\n",
      "    8.69999981   57.5         120.19999695    8.60000038  199.80000305\n",
      "   66.09999847  214.69999695   23.79999924   97.5         204.1000061\n",
      "  195.3999939    67.80000305  281.3999939    69.19999695  147.30000305\n",
      "  218.3999939   237.3999939    13.19999981  228.30000305   62.29999924\n",
      "  262.8999939   142.8999939   240.1000061   248.80000305   70.59999847\n",
      "  292.8999939   112.90000153   97.19999695  265.6000061    95.69999695\n",
      "  290.70001221  266.8999939    74.69999695   43.09999847  228.          202.5\n",
      "  177.          293.6000061   206.8999939    25.10000038  175.1000061\n",
      "   89.69999695  239.8999939   227.19999695   66.90000153  199.80000305\n",
      "  100.40000153  216.3999939   182.6000061   262.70001221  198.8999939\n",
      "    7.30000019  136.19999695  210.80000305  210.69999695   53.5\n",
      "  261.29998779  239.30000305  102.69999695  131.1000061    69.           31.5\n",
      "  139.30000305  237.3999939   216.80000305  199.1000061   109.80000305\n",
      "   26.79999924  129.3999939   213.3999939    16.89999962   27.5         120.5\n",
      "    5.4000001   116.           76.40000153  239.80000305   75.30000305\n",
      "   68.40000153  213.5         193.19999695   76.30000305  110.69999695\n",
      "   88.30000305  109.80000305  134.30000305   28.60000038  217.69999695\n",
      "  250.8999939   107.40000153  163.30000305  197.6000061   184.8999939\n",
      "  289.70001221  135.19999695  222.3999939   296.3999939   280.20001221\n",
      "  187.8999939   238.19999695  137.8999939    25.           90.40000153\n",
      "   13.10000038  255.3999939   225.80000305  241.69999695  175.69999695\n",
      "  209.6000061    78.19999695   75.09999847  139.19999695   76.40000153\n",
      "  125.69999695   19.39999962  141.30000305   18.79999924  224.\n",
      "  123.09999847  229.5          87.19999695    7.80000019   80.19999695\n",
      "  220.30000305   59.59999847    0.69999999  265.20001221    8.39999962\n",
      "  219.80000305   36.90000153   48.29999924   25.60000038  273.70001221\n",
      "   43.          184.8999939    73.40000153  193.69999695  220.5\n",
      "  104.59999847   96.19999695  140.30000305  240.1000061   243.19999695\n",
      "   38.           44.70000076  280.70001221  121.          197.6000061\n",
      "  171.30000305  187.80000305    4.0999999    93.90000153  149.80000305\n",
      "   11.69999981  131.69999695  172.5          85.69999695  188.3999939\n",
      "  163.5         117.19999695  234.5          17.89999962  206.80000305\n",
      "  215.3999939   284.29998779   50.          164.5          19.60000038\n",
      "  168.3999939   222.3999939   276.8999939   248.3999939   170.19999695\n",
      "  276.70001221  165.6000061   156.6000061   218.5          56.20000076\n",
      "  287.6000061   253.80000305  205.          139.5         191.1000061   286.\n",
      "   18.70000076   39.5          75.5          17.20000076  166.80000305\n",
      "  149.69999695   38.20000076   94.19999695  177.          283.6000061\n",
      "  232.1000061 ]\n",
      "\n",
      "-------Mean advertising value for TV-------\n",
      "147.042\n"
     ]
    }
   ],
   "source": [
    "# Think of a session as a file handle. So we must close it. Hence this way of writing is better. \n",
    "with tf.Session() as session:\n",
    "    result = session.run(x_tensor)\n",
    "    print(\"\\n-------Advertising Data for TV-------\")\n",
    "    print(result)\n",
    "    result_mean = session.run(x_mean)\n",
    "    print(\"\\n-------Mean advertising value for TV-------\")\n",
    "    print(result_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Session\n",
    "Consider this : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    res = sess.run(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, what just happened?**\n",
    "1. First of all, see it's so good that we only ran part of our whole graph. Just one ***x_mean***\n",
    "2. Secondly, x_mean due to its definition will create a node (operation) in the graph for mean operation\n",
    "3. Thirdly, since mean operation takes a x_tensor, we check its definition and that is done via convert_to_tensor thing\n",
    "\n",
    "**So, there would be total of 2 nodes in this session ka graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's complicate shit now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Single Variable Regression**\n",
    "\n",
    "y = Mx + C\n",
    "find M and C basically. Slow & Intercept.\n",
    "\n",
    "If you work out math, you can get their formulaes (As in slide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 -  Given TV x, what is the Sale value y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# First, I need average\n",
    "adv = pd.read_csv('Advertising.csv')\n",
    "tv_budget_x = adv.TV.tolist()\n",
    "x_tens = tf.convert_to_tensor(tv_budget_x)\n",
    "x_avg_tensor = tf.reduce_mean(x_tens)\n",
    "print(x_avg_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we gotta subtract the difference and square it up and sum it up. \n",
    "Can't do it cuz both should be tensor, but X is 200 dimension but xavg is 0 dimension. \n",
    "We'll use tf.fill to make shapes compatible, so we can do subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(200,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Let's check shape of x_tens\n",
    "print(x_tens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_avg_tensor_filled = tf.fill([200],x_avg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_avg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Fill:0\", shape=(200,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_avg_tensor_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we can subtract and get a new tensor of dimension 200. \n",
    "Then we square each term up in it.\n",
    "Then we reduce_sum along axis 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/subtract\n",
    "x_difference_tensor = tf.subtract(x_tens,x_avg_tensor_filled)\n",
    "# https://www.tensorflow.org/api_docs/python/tf/square\n",
    "x_diff_tensor_square = tf.square(x_difference_tensor)\n",
    "# reduce_sum across axis 0 \n",
    "#denominator_term = tf.reduce_sum(x_diff_tensor_square,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denominator_tensor = tf.reduce_sum(x_diff_tensor_square, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46682e+06\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    deno_res = session.run(denominator_tensor)\n",
    "    print(deno_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay, now the numerator part**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we first of all need an average of y. Avg of sales.\n",
    "So, let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.1, 10.4, 9.3, 18.5, 12.9, 7.2, 11.8, 13.2, 4.8, 10.6, 8.6, 17.4, 9.2, 9.7, 19.0, 22.4, 12.5, 24.4, 11.3, 14.6, 18.0, 12.5, 5.6, 15.5, 9.7, 12.0, 15.0, 15.9, 18.9, 10.5, 21.4, 11.9, 9.6, 17.4, 9.5, 12.8, 25.4, 14.7, 10.1, 21.5, 16.6, 17.1, 20.7, 12.9, 8.5, 14.9, 10.6, 23.2, 14.8, 9.7, 11.4, 10.7, 22.6, 21.2, 20.2, 23.7, 5.5, 13.2, 23.8, 18.4, 8.1, 24.2, 15.7, 14.0, 18.0, 9.3, 9.5, 13.4, 18.9, 22.3, 18.3, 12.4, 8.8, 11.0, 17.0, 8.7, 6.9, 14.2, 5.3, 11.0, 11.8, 12.3, 11.3, 13.6, 21.7, 15.2, 12.0, 16.0, 12.9, 16.7, 11.2, 7.3, 19.4, 22.2, 11.5, 16.9, 11.7, 15.5, 25.4, 17.2, 11.7, 23.8, 14.8, 14.7, 20.7, 19.2, 7.2, 8.7, 5.3, 19.8, 13.4, 21.8, 14.1, 15.9, 14.6, 12.6, 12.2, 9.4, 15.9, 6.6, 15.5, 7.0, 11.6, 15.2, 19.7, 10.6, 6.6, 8.8, 24.7, 9.7, 1.6, 12.7, 5.7, 19.6, 10.8, 11.6, 9.5, 20.8, 9.6, 20.7, 10.9, 19.2, 20.1, 10.4, 11.4, 10.3, 13.2, 25.4, 10.9, 10.1, 16.1, 11.6, 16.6, 19.0, 15.6, 3.2, 15.3, 10.1, 7.3, 12.9, 14.4, 13.3, 14.9, 18.0, 11.9, 11.9, 8.0, 12.2, 17.1, 15.0, 8.4, 14.5, 7.6, 11.7, 11.5, 27.0, 20.2, 11.7, 11.8, 12.6, 10.5, 12.2, 8.7, 26.2, 17.6, 22.6, 10.3, 17.3, 15.9, 6.7, 10.8, 9.9, 5.9, 19.6, 17.3, 7.6, 9.7, 12.8, 25.5, 13.4]\n"
     ]
    }
   ],
   "source": [
    "sales_y = adv.Sales.tolist()\n",
    "print(sales_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69727.7\n"
     ]
    }
   ],
   "source": [
    "y_tensor = tf.convert_to_tensor(sales_y)\n",
    "y_mean_tensor = tf.reduce_mean(input_tensor=y_tensor)\n",
    "y_mean_filled_tensor = tf.fill([200],y_mean_tensor)\n",
    "\n",
    "# We need to multiple (x-x_avg)*(y-y_avg) and sum this thing up --- that would be our numerator\n",
    "# x-x_avg we already have in x_difference_tensor\n",
    "y_difference_tensor = tf.subtract(y_tensor,y_mean_filled_tensor)\n",
    "\n",
    "numerator_tensor = tf.reduce_sum(tf.multiply(x_difference_tensor,y_difference_tensor),0)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    num_res = session.run(numerator_tensor)\n",
    "    print(num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your slope (M) value is : \n",
      "0.0475366\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    num_res = session.run(numerator_tensor)\n",
    "    deno_res = session.run(denominator_tensor)\n",
    "    print(\"Your slope (M) value is : \")\n",
    "    print(num_res/deno_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard - Visalize automatically via graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is teh way you do it in your session\n",
    "```writer = tf.summary.FileWriter('./graphs',sess.graph)```\n",
    "and then you just need to call :\n",
    "```tensorboard --logdir=./graphs/```\n",
    "\n",
    "It starts a webserver which will show you a pretty graph. \n",
    "The graph would be pretty only, if all operations are in different methods/scopes in your python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your slope (M) value is : \n",
      "0.0475366\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.summary.FileWriter('./graphs',session.graph)\n",
    "    num_res = session.run(numerator_tensor)\n",
    "    deno_res = session.run(denominator_tensor)\n",
    "    print(\"Your slope (M) value is : \")\n",
    "    print(num_res/deno_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ran the tensorboard on terminal***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To make it pretty, we define scopes. We write like this:\n",
    "```with tf.name_scope(\"Denominator\"):\n",
    "    x_term = gen_term(x_tensor,x_mean)\n",
    "    denominator = tf.reduce_sum(whatever.....)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Machine Learning\n",
    "\n",
    "We cheated because we told the program what the formulae is for slope and intercept. \n",
    "Program should learn itself those values.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we worked with till now is constant tensors. \n",
    "We need to now work with **variable tensors**.\n",
    "\n",
    "We're gonna use variable tensor and initially just keept these variable tensors as 0. Then we're gonna do gradient descent and reduce loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Placeholder tensors** - when we define our graph, we don't know how big our input data is. We don't know the dimension of data at all. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our placeholders are expecting us to feed in a python variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "[[ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# constant tensor\n",
    "w1 = tf.ones([2,2])\n",
    "\n",
    "# variable tensor\n",
    "w2 = tf.Variable(tf.zeros((2,2)))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print(session.run(w1))\n",
    "    # NOW THIS IS IMPORTANT. UNLESS WE INITIALIZE OUR VARIABLE TENSORS, TensorFlow blows up\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print(session.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVLR again now using ML\n",
    "\n",
    "We'll use gradient descent. 2 types - Stochastic and Batch\n",
    "\n",
    "We have 200 samples in data. How ML goes is - \n",
    "\n",
    "1. **If Batch Gradient Descent** : \n",
    "Let's guess slope and intercept as 0 , 0 for all 200 samples. We calculate value of cost and all (differentiation). Change values of slope and intercept. Then go over again... \n",
    "\n",
    "2. **If Stochastic Gradient Descent** : \n",
    "For each sample, we'll take a new value of slope & intercept. Gives faster convergence.\n",
    "\n",
    "\n",
    "#### Batch Grad Desc\n",
    "```\n",
    "slope = intercept = 0\n",
    "for i in 1000:\n",
    "    for k in data:\n",
    "        y[k] = x[k] * slope + intercept\n",
    "        j = <whatever error>\n",
    "    slope = differentiate(j/slope)\n",
    "    intercept = differentiate(j/intercept)\n",
    "    ```\n",
    "    \n",
    "### Stochastic Grad Desc\n",
    "```\n",
    "slope = intercept = 0\n",
    "for i in 1000:\n",
    "    for k in data:\n",
    "        y[k] = x[k] * slope + intercept\n",
    "        j = <whatever error>\n",
    "        slope = differentiate(j/slope)\n",
    "        intercept = differentiate(j/intercept)\n",
    "    ```\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", name=\"X\")\n",
    "Y = tf.placeholder(\"float32\", name=\"Y\")\n",
    "# IMPORTANT - We will feed these in during training using feed_dict dictionary. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Model\"):\n",
    "    m = tf.Variable(0.0, name=\"b0\", dtype=\"float32\")\n",
    "    c = tf.Variable(0.0, name=\"b1\", dtype=\"float32\")\n",
    "    y_model = tf.add(tf.multiply(X,m),c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"CostFunction\"):\n",
    "    cost = tf.pow(Y-y_model, 2, name=\"cost\")/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do Stochastic Gradient Descent**\n",
    "\n",
    "IMPORTANT : Also, we need to normalize our data. If we don't, our slope and intercept would reach a NaN value very soon.\n",
    "\n",
    "`budget_tv_x = adv.TV.tolist() / np.max(adv.TV.tolist())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll describe our GradientDescent Optimizer that tf provides\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tv_budget_x = adv.TV.tolist() / np.max(adv.TV.tolist())\n",
    "sales_y = adv.Sales.tolist() / np.max(adv.Sales.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([  1.33785550e-02,   1.56959228e-03,   1.99760590e-03,\n         1.41473273e-02,   4.10670368e-03,   6.12703275e-08,\n         3.61770834e-03,   3.60597711e-04,   3.90403671e-03,\n         2.18747873e-02,   1.17869501e-03,   1.36682153e-04,\n         1.14811119e-03,   1.98002788e-03,   4.45561158e-03,\n         2.77528353e-02,   4.31589782e-03,   1.25950193e-02,\n         1.05825660e-03,   4.84787597e-04,   5.20396105e-04,\n         2.09701601e-02,   2.23166239e-03,   3.01933661e-03,\n         6.52144593e-07,   3.59313712e-02,   1.44056976e-03,\n         3.49504175e-03,   7.48255625e-05,   9.68625827e-05,\n         3.75834614e-04,   3.59494916e-05,   2.18500686e-03,\n         2.65076477e-03,   2.25636456e-03,   4.12534848e-02,\n         2.44653374e-02,   1.31669585e-02,   1.12218375e-03,\n         1.05182976e-02,   3.46020570e-05,   2.56312359e-03,\n         3.42965407e-08,   9.30814538e-03,   1.94263281e-04,\n         2.14415832e-05,   1.26472078e-04,   1.75059587e-02,\n         5.17184567e-03,   4.24718201e-05,   1.61162913e-02,\n         4.79952869e-04,   2.12473124e-02,   2.28167418e-02,\n         6.47369772e-04,   3.85311432e-02,   1.80934090e-03,\n         7.56341819e-07,   3.39083634e-02,   1.83569861e-03,\n         1.01045531e-03,   1.74075607e-02,   4.01496375e-03,\n         3.80215258e-03,   1.72051247e-02,   3.84127459e-04,\n         1.03576831e-03,   2.70890524e-07,   5.19827125e-04,\n         1.88818965e-02,   2.98377243e-03,   1.19825992e-04,\n         3.87481879e-04,   2.50456948e-03,   8.00313228e-06,\n         8.61626060e-04,   9.57507989e-04,   2.00759456e-03,\n         2.06260546e-03,   1.11647428e-03,   1.34607195e-03,\n         2.34174002e-02,   6.22981403e-04,   8.79072119e-03,\n         1.58241019e-02,   3.70153051e-04,   1.76826946e-03,\n         1.08389640e-02,   2.57319841e-03,   1.52670266e-02,\n         2.58976012e-03,   4.76692541e-04,   3.64161236e-03,\n         8.55029840e-03,   9.30233946e-05,   3.89298820e-03,\n         1.35402549e-02,   1.16788510e-06,   1.64134093e-02,\n         1.10519184e-02,   2.16513947e-02,   6.06781570e-03,\n         1.89609397e-02,   6.63351035e-04,   4.75372607e-03,\n         2.37638187e-02,   3.99356533e-04,   3.82841495e-03,\n         3.02204094e-03,   5.77369239e-04,   1.14153586e-02,\n         8.72563664e-03,   6.93088048e-04,   4.52093693e-04,\n         1.16174519e-02,   3.51100182e-03,   9.47555760e-04,\n         6.84612489e-04,   6.86801970e-03,   8.26373405e-04,\n         2.81274063e-03,   3.07172799e-04,   2.30277628e-02,\n         4.59253043e-03,   2.86829937e-03,   6.63084938e-05,\n         2.05890479e-04,   2.17110431e-03,   3.83851118e-02,\n         6.47024535e-06,   1.86273679e-02,   3.03031690e-02,\n         1.49489113e-03,   3.96611867e-03,   3.54343955e-03,\n         4.39947238e-03,   1.56075484e-03,   7.56461930e-04,\n         4.21422214e-04,   1.82527713e-02,   2.83658883e-04,\n         7.20743416e-03,   5.65547217e-03,   1.22343143e-03,\n         2.68164740e-06,   6.70876773e-03,   1.68557130e-02,\n         3.45328860e-02,   3.69425607e-03,   9.93075082e-04,\n         1.08729526e-02,   5.71504293e-04,   1.43141689e-04,\n         1.15479706e-02,   4.24868449e-06,   9.76135209e-03,\n         1.13699501e-02,   9.78837349e-03,   7.34689763e-07,\n         9.86610758e-06,   2.10191080e-04,   4.15115897e-03,\n         4.46829014e-04,   8.27257521e-03,   1.28434331e-04,\n         2.46253777e-02,   9.56456643e-05,   1.31531013e-02,\n         8.79440722e-06,   1.89199429e-02,   3.83641076e-04,\n         3.80072424e-06,   7.87263161e-06,   6.41917717e-03,\n         2.32202597e-02,   3.45605537e-02,   1.86559313e-03,\n         6.78216293e-03,   4.49109264e-02,   2.81687058e-03,\n         9.38973855e-03,   1.66949444e-02,   3.77346092e-04,\n         2.30045766e-02,   9.98667907e-04,   2.55725533e-02,\n         6.54709339e-03,   1.47182238e-03,   1.34767992e-02,\n         6.38015277e-04,   3.16965580e-03,   1.42884644e-04,\n         1.96678890e-03,   1.65792275e-02,   8.05500709e-03,\n         6.70396199e-04,   1.63228845e-03,   3.84226441e-03,\n         1.91282649e-02,   1.31474175e-02], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 270\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    271\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2707\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2796\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[0;32m-> 2797\u001b[0;31m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-721272a4fa78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtv_budget_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msales_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfinal_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfinal_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"M=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"c=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1109\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \"\"\"\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    272\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    273\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([  1.33785550e-02,   1.56959228e-03,   1.99760590e-03,\n         1.41473273e-02,   4.10670368e-03,   6.12703275e-08,\n         3.61770834e-03,   3.60597711e-04,   3.90403671e-03,\n         2.18747873e-02,   1.17869501e-03,   1.36682153e-04,\n         1.14811119e-03,   1.98002788e-03,   4.45561158e-03,\n         2.77528353e-02,   4.31589782e-03,   1.25950193e-02,\n         1.05825660e-03,   4.84787597e-04,   5.20396105e-04,\n         2.09701601e-02,   2.23166239e-03,   3.01933661e-03,\n         6.52144593e-07,   3.59313712e-02,   1.44056976e-03,\n         3.49504175e-03,   7.48255625e-05,   9.68625827e-05,\n         3.75834614e-04,   3.59494916e-05,   2.18500686e-03,\n         2.65076477e-03,   2.25636456e-03,   4.12534848e-02,\n         2.44653374e-02,   1.31669585e-02,   1.12218375e-03,\n         1.05182976e-02,   3.46020570e-05,   2.56312359e-03,\n         3.42965407e-08,   9.30814538e-03,   1.94263281e-04,\n         2.14415832e-05,   1.26472078e-04,   1.75059587e-02,\n         5.17184567e-03,   4.24718201e-05,   1.61162913e-02,\n         4.79952869e-04,   2.12473124e-02,   2.28167418e-02,\n         6.47369772e-04,   3.85311432e-02,   1.80934090e-03,\n         7.56341819e-07,   3.39083634e-02,   1.83569861e-03,\n         1.01045531e-03,   1.74075607e-02,   4.01496375e-03,\n         3.80215258e-03,   1.72051247e-02,   3.84127459e-04,\n         1.03576831e-03,   2.70890524e-07,   5.19827125e-04,\n         1.88818965e-02,   2.98377243e-03,   1.19825992e-04,\n         3.87481879e-04,   2.50456948e-03,   8.00313228e-06,\n         8.61626060e-04,   9.57507989e-04,   2.00759456e-03,\n         2.06260546e-03,   1.11647428e-03,   1.34607195e-03,\n         2.34174002e-02,   6.22981403e-04,   8.79072119e-03,\n         1.58241019e-02,   3.70153051e-04,   1.76826946e-03,\n         1.08389640e-02,   2.57319841e-03,   1.52670266e-02,\n         2.58976012e-03,   4.76692541e-04,   3.64161236e-03,\n         8.55029840e-03,   9.30233946e-05,   3.89298820e-03,\n         1.35402549e-02,   1.16788510e-06,   1.64134093e-02,\n         1.10519184e-02,   2.16513947e-02,   6.06781570e-03,\n         1.89609397e-02,   6.63351035e-04,   4.75372607e-03,\n         2.37638187e-02,   3.99356533e-04,   3.82841495e-03,\n         3.02204094e-03,   5.77369239e-04,   1.14153586e-02,\n         8.72563664e-03,   6.93088048e-04,   4.52093693e-04,\n         1.16174519e-02,   3.51100182e-03,   9.47555760e-04,\n         6.84612489e-04,   6.86801970e-03,   8.26373405e-04,\n         2.81274063e-03,   3.07172799e-04,   2.30277628e-02,\n         4.59253043e-03,   2.86829937e-03,   6.63084938e-05,\n         2.05890479e-04,   2.17110431e-03,   3.83851118e-02,\n         6.47024535e-06,   1.86273679e-02,   3.03031690e-02,\n         1.49489113e-03,   3.96611867e-03,   3.54343955e-03,\n         4.39947238e-03,   1.56075484e-03,   7.56461930e-04,\n         4.21422214e-04,   1.82527713e-02,   2.83658883e-04,\n         7.20743416e-03,   5.65547217e-03,   1.22343143e-03,\n         2.68164740e-06,   6.70876773e-03,   1.68557130e-02,\n         3.45328860e-02,   3.69425607e-03,   9.93075082e-04,\n         1.08729526e-02,   5.71504293e-04,   1.43141689e-04,\n         1.15479706e-02,   4.24868449e-06,   9.76135209e-03,\n         1.13699501e-02,   9.78837349e-03,   7.34689763e-07,\n         9.86610758e-06,   2.10191080e-04,   4.15115897e-03,\n         4.46829014e-04,   8.27257521e-03,   1.28434331e-04,\n         2.46253777e-02,   9.56456643e-05,   1.31531013e-02,\n         8.79440722e-06,   1.89199429e-02,   3.83641076e-04,\n         3.80072424e-06,   7.87263161e-06,   6.41917717e-03,\n         2.32202597e-02,   3.45605537e-02,   1.86559313e-03,\n         6.78216293e-03,   4.49109264e-02,   2.81687058e-03,\n         9.38973855e-03,   1.66949444e-02,   3.77346092e-04,\n         2.30045766e-02,   9.98667907e-04,   2.55725533e-02,\n         6.54709339e-03,   1.47182238e-03,   1.34767992e-02,\n         6.38015277e-04,   3.16965580e-03,   1.42884644e-04,\n         1.96678890e-03,   1.65792275e-02,   8.05500709e-03,\n         6.70396199e-04,   1.63228845e-03,   3.84226441e-03,\n         1.91282649e-02,   1.31474175e-02], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "# ACTUAL ALGORITHM\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "final_m = 0.0\n",
    "final_c = 0.0\n",
    "\n",
    "# We will do 200 iterations!\n",
    "for i in range(200):\n",
    "    for (j,(x,y)) in enumerate(zip(tv_budget_x, sales_y)):\n",
    "        feed_dict = {X:x, Y:y}\n",
    "        train = session.run(train_op, feed_dict=feed_dict)\n",
    "        idx = (i * len(tv_budget_x)) + j\n",
    "    if (i+1) % 50 == 0:\n",
    "        c = session.run(cost, feed_dict={X:tv_budget_x, Y:sales_y})\n",
    "        final_m = session.run(m)\n",
    "        final_c = session.run(c)\n",
    "        print(\"Epoch:\", i, \"M=\", session.run(m), \"c=\", session.run(c))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard showing training live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They talk via summary files and show it in graphs.\n",
    "\n",
    "**How you do it?**\n",
    "You annotate methods.\n",
    "\n",
    "\n",
    "`tf.summary.scalar(\"foo\", bar)`\n",
    "\n",
    "^ bar is the variable and foo is what it'll be called\n",
    "\n",
    "`tf.summary.histogram(\"foo\",bar)`\n",
    "\n",
    "^ histogram of how it is changing\n",
    "\n",
    "`tf.summary.merge_all()`\n",
    "\n",
    "^ to write all summary stuff in one operation. Extremely crucial n important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now lets have some code **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I RAN ex3.py after this. Run it on terminal, it works.\n",
    "# On jupyter it was giving some error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***checked tensorboard***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PENDING - paste image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up unti now, we used regression. With regression, best we can do is binary classification. Use linear regression, get a value, scale it down to 0-1. Then do binary classification.\n",
    "When you do so, it is called **logistic regression**.\n",
    "\n",
    "How you scale it b/w 0 and 1? \n",
    "You use **activation functions**\n",
    "\n",
    "Example : \n",
    "1. Sigmoid function   `(e^X / (1+e^X)`   {X is the function}\n",
    "\n",
    "Others : relu, tanu, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sigmoid**\n",
    "Sigmoid is also called **logistic function**\n",
    "\n",
    "```\n",
    "p(X) = e^(MX+C) / (1+e^(MX+C))\n",
    "\n",
    "=> MX+C = log( p(X) / (1-p(x)))\n",
    "```\n",
    "\n",
    "RHS here is just your linear regression formulae! \n",
    "\n",
    "The last line log wala RHS is called logits or odds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost in logistic regression?**\n",
    "\n",
    "It is cross entropy. \n",
    "\n",
    "```tf.reduce_mean( -(y*tf.log(a) + (1-y)*tf.log(1-a)))```\n",
    "\n",
    "^ **Problem?** \n",
    "log(0) possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code is in show1.py. \n",
    "Not running in Jupyter cuz causes problems. At least tensorboard causes issues.\n",
    "\n",
    "#### fixed code in show1-fix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synapses** --- multiply weight with input and give as output\n",
    "\n",
    "**Neuron** ---- add all inputs, run through activation function and output that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last output and First input are not changeable. \n",
    "Things configurable are hidden layer. \n",
    "You can decide : \n",
    "    1. Num of hidden layers\n",
    "    2. Num of neurons in hidden layer\n",
    "    \n",
    "But by default, in NN, every neuron of prev layer is connected to every neuron of next one. \n",
    "\n",
    "Now, \n",
    "1. you pick initial weights by yourself. Any random stuff.\n",
    "2. ***Propagate forward***\n",
    "3. Check cost\n",
    "4. ***Propagate backward*** (change weight)\n",
    "5. Propagate forward again . . .\n",
    "all over and over for 1000 epochs.\n",
    "\n",
    "Backward propagation happens using partial differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
