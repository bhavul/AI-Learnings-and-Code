{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from hyperdash import monitor_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"./data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.examples.tutorials.mnist.input_data' from '/Users/bhavul.g/.virtualenvs/ailearn/lib/python3.5/site-packages/tensorflow/examples/tutorials/mnist/input_data.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\n",
      "\"\"\"Functions for downloading and reading MNIST data.\"\"\"\n",
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "\n",
      "import gzip\n",
      "import os\n",
      "import tempfile\n",
      "\n",
      "import numpy\n",
      "from six.moves import urllib\n",
      "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
      "import tensorflow as tf\n",
      "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So it is a python file essentially. A module. \n",
    "\n",
    "import inspect\n",
    "src = inspect.getsource(input_data)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_data_sets(train_dir,\n",
      "                   fake_data=False,\n",
      "                   one_hot=False,\n",
      "                   dtype=dtypes.float32,\n",
      "                   reshape=True,\n",
      "                   validation_size=5000,\n",
      "                   seed=None):\n",
      "  if fake_data:\n",
      "\n",
      "    def fake():\n",
      "      return DataSet(\n",
      "          [], [], fake_data=True, one_hot=one_hot, dtype=dtype, seed=seed)\n",
      "\n",
      "    train = fake()\n",
      "    validation = fake()\n",
      "    test = fake()\n",
      "    return base.Datasets(train=train, validation=validation, test=test)\n",
      "\n",
      "  TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
      "  TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
      "  TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
      "  TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
      "\n",
      "  local_file = base.maybe_download(TRAIN_IMAGES, train_dir,\n",
      "                                   SOURCE_URL + TRAIN_IMAGES)\n",
      "  with open(local_file, 'rb') as f:\n",
      "    train_images = extract_images(f)\n",
      "\n",
      "  local_file = base.maybe_download(TRAIN_LABELS, train_dir,\n",
      "                                   SOURCE_URL + TRAIN_LABELS)\n",
      "  with open(local_file, 'rb') as f:\n",
      "    train_labels = extract_labels(f, one_hot=one_hot)\n",
      "\n",
      "  local_file = base.maybe_download(TEST_IMAGES, train_dir,\n",
      "                                   SOURCE_URL + TEST_IMAGES)\n",
      "  with open(local_file, 'rb') as f:\n",
      "    test_images = extract_images(f)\n",
      "\n",
      "  local_file = base.maybe_download(TEST_LABELS, train_dir,\n",
      "                                   SOURCE_URL + TEST_LABELS)\n",
      "  with open(local_file, 'rb') as f:\n",
      "    test_labels = extract_labels(f, one_hot=one_hot)\n",
      "\n",
      "  if not 0 <= validation_size <= len(train_images):\n",
      "    raise ValueError(\n",
      "        'Validation size should be between 0 and {}. Received: {}.'\n",
      "        .format(len(train_images), validation_size))\n",
      "\n",
      "  validation_images = train_images[:validation_size]\n",
      "  validation_labels = train_labels[:validation_size]\n",
      "  train_images = train_images[validation_size:]\n",
      "  train_labels = train_labels[validation_size:]\n",
      "\n",
      "  \n",
      "  options = dict(dtype=dtype, reshape=reshape, seed=seed)\n",
      "  \n",
      "  train = DataSet(train_images, train_labels, **options)\n",
      "  validation = DataSet(validation_images, validation_labels, **options)\n",
      "  test = DataSet(test_images, test_labels, **options)\n",
      "  \n",
      "  return base.Datasets(train=train, validation=validation, test=test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay, so actual logic must be in read_data_sets function.\n",
    "\n",
    "srcMethod = inspect.getsource(input_data.read_data_sets)\n",
    "print(srcMethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def extract_labels(f, one_hot=False, num_classes=10):\n",
      "  \"\"\"Extract the labels into a 1D uint8 numpy array [index].\n",
      "\n",
      "  Args:\n",
      "    f: A file object that can be passed into a gzip reader.\n",
      "    one_hot: Does one hot encoding for the result.\n",
      "    num_classes: Number of classes for the one hot encoding.\n",
      "\n",
      "  Returns:\n",
      "    labels: a 1D uint8 numpy array.\n",
      "\n",
      "  Raises:\n",
      "    ValueError: If the bystream doesn't start with 2049.\n",
      "  \"\"\"\n",
      "  print('Extracting', f.name)\n",
      "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
      "    magic = _read32(bytestream)\n",
      "    if magic != 2049:\n",
      "      raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n",
      "                       (magic, f.name))\n",
      "    num_items = _read32(bytestream)\n",
      "    buf = bytestream.read(num_items)\n",
      "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
      "    if one_hot:\n",
      "      return dense_to_one_hot(labels, num_classes)\n",
      "    return labels\n",
      "\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "def extract_images(f):\n",
      "  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n",
      "\n",
      "  Args:\n",
      "    f: A file object that can be passed into a gzip reader.\n",
      "\n",
      "  Returns:\n",
      "    data: A 4D uint8 numpy array [index, y, x, depth].\n",
      "\n",
      "  Raises:\n",
      "    ValueError: If the bytestream does not start with 2051.\n",
      "\n",
      "  \"\"\"\n",
      "  print('Extracting', f.name)\n",
      "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
      "    magic = _read32(bytestream)\n",
      "    if magic != 2051:\n",
      "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
      "                       (magic, f.name))\n",
      "    num_images = _read32(bytestream)\n",
      "    rows = _read32(bytestream)\n",
      "    cols = _read32(bytestream)\n",
      "    buf = bytestream.read(rows * cols * num_images)\n",
      "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
      "    data = data.reshape(num_images, rows, cols, 1)\n",
      "    return data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The above code seems very intuitive. Just extract_images and extract_labels could be checked\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "src_extract_labels = inspect.getsource(mnist.extract_labels)\n",
    "src_extract_images = inspect.getsource(mnist.extract_images)\n",
    "\n",
    "print(src_extract_labels)\n",
    "print(\"\\n------------------------------------------------------------------\\n\")\n",
    "print(src_extract_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11dba5208>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11dba51d0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11dba5278>)\n"
     ]
    }
   ],
   "source": [
    "# Cool. Easy enough to understand. Let's check what is in data now.\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "print(len(data.train.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.38039219  0.37647063\n",
      "  0.3019608   0.46274513  0.2392157   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.35294119  0.5411765\n",
      "  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869\n",
      "  0.98431379  0.98431379  0.97254908  0.99607849  0.96078438  0.92156869\n",
      "  0.74509805  0.08235294  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54901963  0.98431379  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.74117649  0.09019608\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.88627458  0.99607849  0.81568635\n",
      "  0.78039223  0.78039223  0.78039223  0.78039223  0.54509807  0.2392157\n",
      "  0.2392157   0.2392157   0.2392157   0.2392157   0.50196081  0.8705883\n",
      "  0.99607849  0.99607849  0.74117649  0.08235294  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14901961  0.32156864  0.0509804   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.13333334  0.83529419  0.99607849  0.99607849  0.45098042  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.41568631  0.6156863   0.99607849  0.99607849  0.95294124  0.20000002\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.09803922  0.45882356  0.89411771\n",
      "  0.89411771  0.89411771  0.99215692  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.94117653  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.26666668  0.4666667   0.86274517\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.55686277  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.14509805  0.73333335  0.99215692\n",
      "  0.99607849  0.99607849  0.99607849  0.87450987  0.80784321  0.80784321\n",
      "  0.29411766  0.26666668  0.84313732  0.99607849  0.99607849  0.45882356\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.44313729\n",
      "  0.8588236   0.99607849  0.94901967  0.89019614  0.45098042  0.34901962\n",
      "  0.12156864  0.          0.          0.          0.          0.7843138\n",
      "  0.99607849  0.9450981   0.16078432  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.66274512  0.99607849  0.6901961   0.24313727  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18823531\n",
      "  0.90588242  0.99607849  0.91764712  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.07058824  0.48627454  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32941177  0.99607849  0.99607849  0.65098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.54509807  0.99607849  0.9333334   0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.82352948  0.98039222  0.99607849  0.65882355  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.94901967  0.99607849  0.93725497  0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.34901962  0.98431379  0.9450981   0.33725491  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01960784  0.80784321  0.96470594  0.6156863   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.01568628  0.45882356  0.27058825  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Check one example\n",
    "\n",
    "print(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "# What was the dimensions?\n",
    "\n",
    "print(data.train.images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The img above is meant to be  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIrwA0ERfiAowg8ERfiBoAg/ENT/AyErW1pw/s8cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1054cd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AAh. So, must be 28 * 28. Let's reshape and try to plot then. \n",
    "# https://matplotlib.org/users/image_tutorial.html   ------ This tells how we could plot it.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(data.train.images[0].reshape((28,28)))\n",
    "print(\"The img above is meant to be \",data.train.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The img above is meant to be  [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiL8QFCEHwiK8ANBEX4gKMIPBPX/EhqoeSQulYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129f44a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's do another one.\n",
    "imgplot2 = plt.imshow(data.train.images[1].reshape((28,28)))\n",
    "print(\"The img above is meant to be \",data.train.labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training data X :  (55000, 784)\n",
      "Dimensions of training data Y :  (55000, 10)\n",
      "Dimensions of training data X :  (5000, 784)\n",
      "Dimensions of training data Y :  (5000, 10)\n",
      "Dimensions of training data X :  (10000, 784)\n",
      "Dimensions of training data Y :  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's check dimensions\n",
    "\n",
    "print(\"Dimensions of training data X : \",data.train.images.shape)\n",
    "print(\"Dimensions of training data Y : \",data.train.labels.shape)\n",
    "print(\"Dimensions of training data X : \",data.validation.images.shape)\n",
    "print(\"Dimensions of training data Y : \",data.validation.labels.shape)\n",
    "print(\"Dimensions of training data X : \",data.test.images.shape)\n",
    "print(\"Dimensions of training data Y : \",data.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, every row here represents an image / one_hot_label. Instead of a column. This is where it differs from the deeplearning.ai course**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Mini-Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at  0 th iteration is :  0.586658\n",
      "cost at  5 th iteration is :  0.391887\n",
      "cost at  10 th iteration is :  0.342949\n",
      "cost at  15 th iteration is :  0.321183\n"
     ]
    }
   ],
   "source": [
    "# code to add\n",
    "X1 = tf.placeholder(tf.float32, [784, None])\n",
    "Y1 = tf.placeholder(tf.float32, [10, None])\n",
    "\n",
    "# Model is simple W*X + b. \n",
    "# IMPORTANT : If say we're doing for 55000 examples. W would be 10x784, X is 784x55000,  b should ideally be 10,55000. But 55000 is not known from before.\n",
    "# So, the point is, 'Variable' needs initialization which can not have 'None'. So, how do we fix this?\n",
    "# Just keep it as dimension - (10,1). Python, numpy, tf ---- let them do BROADCASTING :-)\n",
    "\n",
    "W1 = tf.Variable(tf.zeros((10,784)))\n",
    "b1 = tf.Variable(tf.zeros((10,1)))           \n",
    "\n",
    "Z1 = tf.matmul(W1,X1) + b1\n",
    "\n",
    "# We'll do a softmax for this so that ever number comes b/w 0 and 1. Together they should sum up to 1. Normalization.\n",
    "Y1_pred_softmax = tf.nn.softmax(Z1)\n",
    "Y1_pred_sigmoid = tf.nn.sigmoid(Z1)\n",
    "\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z1, labels=Y1)\n",
    "# Reduce cost to just one number. \n",
    "cost_mean = tf.reduce_mean(cost) \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost_mean)\n",
    "\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "# 1000 epochs \n",
    "for i in range(20):\n",
    "    session.run(optimizer, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T})\n",
    "    if i%5 == 0:\n",
    "        print(\"cost at \",i,\"th iteration is : \",session.run(cost_mean, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without mini-batches, more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at  0 th iteration is :  0.586658\n",
      "cost at  5 th iteration is :  0.391887\n",
      "cost at  10 th iteration is :  0.342949\n",
      "cost at  15 th iteration is :  0.321183\n",
      "cost at  20 th iteration is :  0.307678\n",
      "cost at  25 th iteration is :  0.297502\n",
      "cost at  30 th iteration is :  0.288973\n",
      "cost at  35 th iteration is :  0.281426\n",
      "cost at  40 th iteration is :  0.274557\n",
      "cost at  45 th iteration is :  0.268211\n",
      "cost at  50 th iteration is :  0.262309\n",
      "cost at  55 th iteration is :  0.256788\n",
      "cost at  60 th iteration is :  0.251614\n",
      "cost at  65 th iteration is :  0.246754\n",
      "cost at  70 th iteration is :  0.242181\n",
      "cost at  75 th iteration is :  0.237871\n",
      "cost at  80 th iteration is :  0.233806\n",
      "cost at  85 th iteration is :  0.229963\n",
      "cost at  90 th iteration is :  0.226329\n",
      "cost at  95 th iteration is :  0.222887\n"
     ]
    }
   ],
   "source": [
    "# code to add\n",
    "X1 = tf.placeholder(tf.float32, [784, None])\n",
    "Y1 = tf.placeholder(tf.float32, [10, None])\n",
    "\n",
    "# Model is simple W*X + b. \n",
    "# IMPORTANT : If say we're doing for 55000 examples. W would be 10x784, X is 784x55000,  b should ideally be 10,55000. But 55000 is not known from before.\n",
    "# So, the point is, 'Variable' needs initialization which can not have 'None'. So, how do we fix this?\n",
    "# Just keep it as dimension - (10,1). Python, numpy, tf ---- let them do BROADCASTING :-)\n",
    "\n",
    "W1 = tf.Variable(tf.zeros((10,784)))\n",
    "b1 = tf.Variable(tf.zeros((10,1)))           \n",
    "\n",
    "Z1 = tf.matmul(W1,X1) + b1\n",
    "\n",
    "# We'll do a softmax for this so that ever number comes b/w 0 and 1. Together they should sum up to 1. Normalization.\n",
    "Y1_pred_softmax = tf.nn.softmax(Z1)\n",
    "Y1_pred_sigmoid = tf.nn.sigmoid(Z1)\n",
    "\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z1, labels=Y1)\n",
    "# Reduce cost to just one number. \n",
    "cost_mean = tf.reduce_mean(cost) \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost_mean)\n",
    "\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "# 1000 epochs \n",
    "for i in range(100):\n",
    "    session.run(optimizer, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T})\n",
    "    if i%5 == 0:\n",
    "        print(\"cost at \",i,\"th iteration is : \",session.run(cost_mean, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at  0 th iteration is :  0.257947\n",
      "cost at  5 th iteration is :  0.15263\n",
      "cost at  10 th iteration is :  0.128502\n",
      "cost at  15 th iteration is :  0.116752\n"
     ]
    }
   ],
   "source": [
    "# code to add\n",
    "X1 = tf.placeholder(tf.float32, [784, None])\n",
    "Y1 = tf.placeholder(tf.float32, [10, None])\n",
    "\n",
    "# Model is simple W*X + b. \n",
    "# IMPORTANT : If say we're doing for 55000 examples. W would be 10x784, X is 784x55000,  b should ideally be 10,55000. But 55000 is not known from before.\n",
    "# So, the point is, 'Variable' needs initialization which can not have 'None'. So, how do we fix this?\n",
    "# Just keep it as dimension - (10,1). Python, numpy, tf ---- let them do BROADCASTING :-)\n",
    "\n",
    "W1 = tf.Variable(tf.zeros((10,784)))\n",
    "b1 = tf.Variable(tf.zeros((10,1)))           \n",
    "\n",
    "Z1 = tf.matmul(W1,X1) + b1\n",
    "\n",
    "# We'll do a softmax for this so that ever number comes b/w 0 and 1. Together they should sum up to 1. Normalization.\n",
    "Y1_pred_softmax = tf.nn.softmax(Z1)\n",
    "Y1_pred_sigmoid = tf.nn.sigmoid(Z1)\n",
    "\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z1, labels=Y1)\n",
    "# Reduce cost to just one number. \n",
    "cost_mean = tf.reduce_mean(cost) \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost_mean)\n",
    "\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "# mini-batches of 1000 (so 55 mini-batches)\n",
    "for i in range(20):\n",
    "    for t in range(55):\n",
    "        X_batch, Y_batch = data.train.next_batch(1000)\n",
    "        session.run(optimizer, feed_dict={X1:X_batch.T, Y1:Y_batch.T})\n",
    "    if i%5 == 0:\n",
    "        print(\"cost at \",i,\"th iteration is : \",session.run(cost_mean, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Adam instead of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at  0 th iteration is :  0.14534\n",
      "cost at  5 th iteration is :  0.0687919\n",
      "cost at  10 th iteration is :  0.0697996\n",
      "cost at  15 th iteration is :  0.0731332\n"
     ]
    }
   ],
   "source": [
    "# code to add\n",
    "X1 = tf.placeholder(tf.float32, [784, None])\n",
    "Y1 = tf.placeholder(tf.float32, [10, None])\n",
    "\n",
    "# Model is simple W*X + b. \n",
    "# IMPORTANT : If say we're doing for 55000 examples. W would be 10x784, X is 784x55000,  b should ideally be 10,55000. But 55000 is not known from before.\n",
    "# So, the point is, 'Variable' needs initialization which can not have 'None'. So, how do we fix this?\n",
    "# Just keep it as dimension - (10,1). Python, numpy, tf ---- let them do BROADCASTING :-)\n",
    "\n",
    "W1 = tf.Variable(tf.zeros((10,784)))\n",
    "b1 = tf.Variable(tf.zeros((10,1)))           \n",
    "\n",
    "Z1 = tf.matmul(W1,X1) + b1\n",
    "\n",
    "# We'll do a softmax for this so that ever number comes b/w 0 and 1. Together they should sum up to 1. Normalization.\n",
    "Y1_pred_softmax = tf.nn.softmax(Z1)\n",
    "Y1_pred_sigmoid = tf.nn.sigmoid(Z1)\n",
    "\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z1, labels=Y1)\n",
    "# Reduce cost to just one number. \n",
    "cost_mean = tf.reduce_mean(cost) \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost_mean)\n",
    "\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "# mini-batches of 1000 (so 55 mini-batches)\n",
    "for i in range(25):\n",
    "    for t in range(55):\n",
    "        X_batch, Y_batch = data.train.next_batch(1000)\n",
    "        session.run(optimizer, feed_dict={X1:X_batch.T, Y1:Y_batch.T})\n",
    "    if i%5 == 0:\n",
    "        print(\"cost at \",i,\"th iteration is : \",session.run(cost_mean, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Mini-batch obviously works better!\n",
    "- AdamOptizer is damn fast. But obviously, now your cost could increase/decrease a bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%monitor_cell \"MNIST 2 layer NN\"\n",
    "## 2 Layer NN\n",
    "\n",
    "# code to add\n",
    "X1 = tf.placeholder(tf.float32, [784, None], name='X1')\n",
    "Y1 = tf.placeholder(tf.float32, [10, None], name='Y1')\n",
    "Y1_cls = tf.argmax(Y1, axis=0)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal((100,784)))\n",
    "b1 = tf.Variable(tf.zeros((1,1)))           \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal((10,100)))\n",
    "b2 = tf.Variable(tf.zeros((1,1)))\n",
    "\n",
    "Z1 = tf.matmul(W1,X1) + b1\n",
    "A1 = tf.nn.relu(Z1)\n",
    "\n",
    "Z2 = tf.matmul(W2,A1) + b2\n",
    "A2 = tf.nn.softmax(Z2)\n",
    "\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z2, labels=Y1)\n",
    "# Reduce cost to just one number. \n",
    "cost_mean = tf.reduce_mean(cost) \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost_mean)\n",
    "\n",
    "# We'll do a softmax for this so that ever number comes b/w 0 and 1. Together they should sum up to 1. Normalization.\n",
    "Y2_pred_axis0 = tf.argmax(A2, axis=0)\n",
    "\n",
    "\n",
    "session = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)\n",
    "\n",
    "# mini-batches of 1000 (so 55 mini-batches)\n",
    "for i in range(1000):\n",
    "    X_batch, Y_batch = data.train.next_batch(1000)\n",
    "    _, cost_mean_val, shapeZ2,pred_axis0 = session.run([optimizer,cost_mean,tf.shape(Z2),Y2_pred_axis0], feed_dict={X1:X_batch.T, Y1:Y_batch.T})\n",
    "    if i%5 == 0:\n",
    "        print(\"cost at \",t,\"th iteration is : \",cost_mean_val,shapeZ2)\n",
    "\n",
    "correct_prediction = tf.equal(Y2_pred_axis0, Y1_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"training accuracy : \",session.run(accuracy, feed_dict={X1:data.train.images.T, Y1:data.train.labels.T}))\n",
    "print(\"testing accuracy : \",session.run(accuracy, feed_dict={X1:data.test.images.T, Y1:data.test.labels.T}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hh1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
