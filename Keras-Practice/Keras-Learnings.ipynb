{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions/Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whole of 'Basics' section, this post was quite helpful : https://machinelearningmastery.com/5-step-life-cycle-neural-network-models-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS. \n",
    "Sequential resides in keras.models\n",
    "While Dense resides in keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NN Architecture model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Importing different sorts of layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "# Importing regularization functions\n",
    "from keras import regularizers\n",
    "\n",
    "# Importing constraints\n",
    "from keras import constraints\n",
    "\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything starts with a Sequential() class instantiation. This class is the container for the architecture for a neural network model in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-33eae3815324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ailearn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    452\u001b[0m                     \u001b[0;31m# know about its input shape. Otherwise, that's an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                         raise ValueError('The first layer in a '\n\u001b[0m\u001b[1;32m    455\u001b[0m                                          \u001b[0;34m'Sequential model must '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                          \u001b[0;34m'get an `input_shape` or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the first layer in a Sequential model must have an input_shape!!**\n",
    "For this we use *input_dim* parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# say 15 features\n",
    "model.add(Dense(2,input_dim=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different sorts of Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense (FC) Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition in docs : \n",
    "\n",
    "`keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)`\n",
    "\n",
    "Understanding Parameters for Dense Layer : \n",
    "\n",
    "- **use_bias** : whether to have the bias (b) term or not\n",
    "- **activation** : which activation function to use. By Default it is None, so you can add an activation layer afterwards. But if you know which one to use then you can specify here itself\n",
    "- **kernel_initializer** : which initializer to use to initialize weights of the layer. Like, you could do it randomly, but random with what distribution? By default it uses 'glorot_uniform', however there are many initializers [here](https://keras.io/initializers/). You could use 'RandomUniform' also.\n",
    "- **bias_initializer** : How to initialize biases. Usually zeros work, so 'zeros' is default\n",
    "- **kernel_regularizer** : Whether to use L1 or L2 regularization to penalize weights. values could be `regularizers.l2(0.01)` or `regularizers.l1(0.01)` or None. It is None by default.\n",
    "- **bias_regularizer** : As we studied, bias regularization is often not really required. So, 'None' works fine here. However you do have same options as above.\n",
    "- **activity_regularizer** : This is regularization applied to the output matrix of a layer. Dunno exactly why...\n",
    "- **kernel_constraint** : You can further have constraints on your weights, that while they optimize during training, they always should follow a certain criteria. Like having norm = 1, or always being non-negative. Or sth else. [All constraints are here](https://keras.io/constraints/).\n",
    "- **bias_constraint** : Same thing as above but for bias values for this layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Simple initiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units = 2 means 2 hidden nodes in this layer!\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='relu', kernel_initializer='RandomUniform', kernel_regularizer=regularizers.l2(0.01), kernel_constraint=constraints.non_neg()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want decoupling, so in which case you add your activation layers separately.\n",
    "\n",
    "Below are some common predictive modeling problem types and the structure and standard activation function that you can use in the output layer:\n",
    "\n",
    "* Regression: Linear activation function or ‘linear’ and the number of neurons matching the number of outputs.\n",
    "* Binary Classification (2 class): Logistic activation function or ‘sigmoid’ and one neuron the output layer.\n",
    "* Multiclass Classification (>2 class): Softmax activation function or ‘softmax’ and one output neuron per class value, assuming a one-hot encoded output pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Layer\n",
    "\n",
    "Just like activation layer, often you wanna add a dropout layer. This is for that purpose only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout definition : `keras.layers.Dropout(rate, noise_shape=None, seed=None)`\n",
    "\n",
    "- rate : intuitive to understand. A number between 0 and 1.\n",
    "- noise_shape : If you wish to keep same dropout for a particular dimension, or you want your dropout thingy to work in a structured way, you use this. [More details here.](https://keras.io/layers/core/)\n",
    "- seed : for python random number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition : `keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)`\n",
    "\n",
    "Some parameters are same as *Dense* layer and they have the same meaning. \n",
    "Let's talk about other params that are exclusive to Conv2D.\n",
    "\n",
    "- **filters** : Number of filters to use. This will decide the depth of output volume\n",
    "- **kernel_size** : 2d shape describing the dimensions of filter matrix. Like, (3,3).\n",
    "- **strides** : Could be a single number like 1 or 2, or a tuple of two numbers (if you wish to have different strides vertically and horizontally)\n",
    "- **padding** : 'valid' or 'same'.\n",
    "- **data_format** : This is important. Some people on the internet follow convention of representing image as (width,height,channel) while some otehr folks use (channel,width,height). This describes which data_format to use. `channels_last` (default) or `channels_first` are the values.\n",
    "- **dilation_rate** : This is for dilated convolutions. Again a single number or tuple of two numbers. By default (1,1). [Check this link](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d) to understand dilated convolutions. The image below should be enough to get an idea of it though : \n",
    "    \n",
    "![dilated-convolution](https://cdn-images-1.medium.com/max/1200/1*SVkgHoFoiMZkjy54zM_SUw.gif)\n",
    "\n",
    "^ Dilated Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We'll use Conv2D (usual). To check out what Conv1D, Conv3D, etc do, check the other notebook I've written for comparisons.\n",
    "\n",
    "cnnModel = Sequential()\n",
    "cnnModel.add(Conv2D(5,(3,3),activation='relu', input_shape=(32,32,3)))\n",
    "cnnModel.add(Conv2D(10,(3,3),activation='relu'))   # input_shape only required in first layer\n",
    "cnnModel.add(Conv2D(20,(3,3), padding='same', activation='relu'))\n",
    "\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other types of convolutional layers in Keras as well, like SeparableConv and Cropping1D. You could check [this post](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d) to learn about different types of convolutions. However, I'm skipping them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening Layers\n",
    "\n",
    "Flattens the input. Does not affect the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnModel.add(Flatten())\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Function Layer (lambda)\n",
    "\n",
    "Wraps arbitrary expression as a Layer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square the input\n",
    "cnnModel.add(Lambda(lambda x: x ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat Layer\n",
    "\n",
    "This repeats the vector n times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 15680)          0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnModel.add(RepeatVector(3))\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Layer\n",
    "\n",
    "You can reshape whatever you have. Like we have (3,15680) as size above. It could also be (12,3920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 15680)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 12, 3920)          0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnModel.add(Reshape((12,3920)))\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-Padding 2D\n",
    "\n",
    "This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 15680)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 12, 3920)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3920, 4, 3)        0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need to reshape to make it look like it has 3 dimensions.\n",
    "cnnModel.add(Reshape((3920,4,3)))\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 15680)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 12, 3920)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3920, 4, 3)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 3924, 8, 3)        0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now, let's add zero padding\n",
    "cnnModel.add(ZeroPadding2D(padding=(2,2)))\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling 2D\n",
    "\n",
    "Again, for upsampling as well there are 1d,2d and 3d. Since we'll work with images, whose channels remain fixed at 3. We do 2D convolution functions.\n",
    "Upsampling repeats the rows and columns of the data by size[0] and size[1] respectively.\n",
    "\n",
    "`keras.layers.UpSampling2D(size=(2, 2), data_format=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 5)         140       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 10)        460       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 20)        1820      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 15680)             0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 3, 15680)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 12, 3920)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3920, 4, 3)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 3924, 8, 3)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 7848, 16, 3)       0         \n",
      "=================================================================\n",
      "Total params: 2,420\n",
      "Trainable params: 2,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnModel.add(UpSampling2D(size=(2,2)))\n",
    "cnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping 2D\n",
    "\n",
    "This crops the image. You can provide `cropping` as just an int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
    "- If int: the same symmetric cropping is applied to width and height.\n",
    "- If tuple of 2 ints: interpreted as two different symmetric cropping values for height and width: (symmetric_height_crop, symmetric_width_crop).\n",
    "- If tuple of 2 tuples of 2 ints: interpreted as ((top_crop, bottom_crop), (left_crop, right_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_6 (Cropping2D)    (None, 24, 20, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 20, 64)        1792      \n",
      "_________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)    (None, 20, 16, 64)        0         \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We'll start a new model because previous model has been fiddled around with a lot and the dimensions are not at all good to explain Cropping.\n",
    "newModel = Sequential()\n",
    "newModel.add(Cropping2D(cropping=((2, 2), (4, 4)),\n",
    "                     input_shape=(28, 28, 3)))\n",
    "# now model.output_shape == (None, 24, 20, 3)\n",
    "newModel.add(Conv2D(64, (3, 3), padding='same'))\n",
    "newModel.add(Cropping2D(cropping=((2, 2), (2, 2))))\n",
    "# now model.output_shape == (None, 20, 16. 64)\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How did this work?**\n",
    "\n",
    "Look at the last two layers. It was 24x20 image. \n",
    "You crop off 2 pixels from the top, 2 pixels from the bottom, 2 pixels from left and 2 from the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxPooling 2D\n",
    "\n",
    "Max pooling operation for temporal data. Btw, similarly we have AveragePooling2D which I'm not writing separately.\n",
    "\n",
    "Definition : `keras.layers.MaxPooling1D(pool_size=2, strides=None, padding='valid')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_6 (Cropping2D)    (None, 24, 20, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 20, 64)        1792      \n",
      "_________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)    (None, 20, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 8, 64)         0         \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Remember we had read f=2, s=2 in MaxPooling sort of halves the output dimensions?\n",
    "newModel.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalMaxPooling2D\n",
    "\n",
    "Definition : `keras.layers.GlobalMaxPooling2D(data_format=None)`\n",
    "    \n",
    "Here, it eats up rows and columns dimensions. So, while input is (batchsize, rows, cols, channels), the output is (batchsize, channels)\n",
    "For each (row,column) data it gives 1 max value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_6 (Cropping2D)    (None, 24, 20, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 20, 64)        1792      \n",
      "_________________________________________________________________\n",
      "cropping2d_7 (Cropping2D)    (None, 20, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 1,792\n",
      "Trainable params: 1,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newModel.add(GlobalMaxPooling2D())\n",
    "newModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locally Connected 2D Convolution\n",
    "\n",
    "The LocallyConnected2D layer works similarly to the Conv2D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n",
    "\n",
    "Definition : `keras.layers.LocallyConnected2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)`\n",
    "\n",
    "[Read more here](https://keras.io/layers/local/#locallyconnected2d)\n",
    "\n",
    "**Not writing example code here because it has never been of use to me till now**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer\n",
    "\n",
    "This helps you output embeddings for text. Now, it does require that input to it is integer indices for words instead of actual text. However, keras itself provides Tokenizer API and if not that you could use one_hot followed by pad_sequences to get data in the integer form. Once you have that, it can be passed to embeddings.\n",
    "\n",
    "[Read about a great example here](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)\n",
    "\n",
    "[Another great explanation here](https://stackoverflow.com/questions/45649520/explain-with-example-how-embedding-layers-in-keras-works)\n",
    "\n",
    "**I'm skipping code for this since haven't used it anywhere yet.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeakyReLu\n",
    "\n",
    "Aah! Yes. So, while all other common activation layers come under 'Activation' layer. Some special ones have their own classes in Layers.\n",
    "These are : \n",
    "    - LeakyReLu\n",
    "    - Softmax\n",
    "    - PReLu\n",
    "    - ELU\n",
    "    - ThresholdReLu\n",
    "    \n",
    "LeakyReLu works a bit better than ReLu. It allows a small gradient when the unit is not active.\n",
    "\n",
    "Definition : `keras.layers.LeakyReLU(alpha=0.3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BatchNormalization\n",
    "\n",
    "Definition : `keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)`\n",
    "\n",
    "Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "\n",
    "**Understanding Parameters**:\n",
    "- **axis**: Integer, the axis that should be normalized (typically the features axis). For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
    "- **momentum**: Momentum for the moving mean and the moving variance.\n",
    "- **epsilon**: Small float added to variance to avoid dividing by zero.\n",
    "- **center**: If True, add offset of beta to normalized tensor. If False, beta is ignored.\n",
    "- **scale**: If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling will be done by the next layer.\n",
    "- **beta_initializer**: Initializer for the beta weight.\n",
    "- **gamma_initializer**: Initializer for the gamma weight.\n",
    "- **moving_mean_initializer**: Initializer for the moving mean.\n",
    "- **moving_variance_initializer**: Initializer for the moving variance.\n",
    "- **beta_regularizer**: Optional regularizer for the beta weight.\n",
    "- **gamma_regularizer**: Optional regularizer for the gamma weight.\n",
    "- **beta_constraint**: Optional constraint for the beta weight.\n",
    "- **gamma_constraint**: Optional constraint for the gamma weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTHER INTERESTING LAYERS\n",
    "\n",
    "[GaussianNoise](https://keras.io/layers/noise/#gaussiannoise) : Adds noise to the data. Data Augmentation technique. To Reduce overfitting. Only active during training.\n",
    "\n",
    "[AlphaDropout](https://keras.io/layers/noise/#alphadropout) : It is Dropout only but it  keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout.\n",
    "               \n",
    "**Sequence Models Related Layers**\n",
    "- [RNN, SimpleRNN, GRU, LSTM, ConvLSTM2D, SimpleRNNCell, GRUCell, LSTMCell, CuDNNGRU, CuDNNLSTM](https://keras.io/layers/recurrent/)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss, optimizer and metric for Model\n",
    "\n",
    "Once we have defined our architecture for the model, the next thing is to define a loss function for it, and the optimizer for it. Optimizer is some or the other variant of Gradient Descent. Loss could be one of many losses.\n",
    "We use `compile` method of Keras to attach these to our model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelA = Sequential()\n",
    "modelA.add(Dense(5, input_dim=2))\n",
    "modelA.add(Activation('relu'))\n",
    "modelA.add(Dense(1))\n",
    "modelA.add(Activation('sigmoid'))\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also specify metrics to collect while fitting your model in addition to the loss function. Generally, the most useful additional metric to collect is accuracy for classification problems. The metrics to collect are specified by name in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 5)                 15        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's use stochastic gradient descent (update weights with every example!) and loss as mean squared error. Basic of the most basic stuff!\n",
    "modelA.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\n",
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some standard loss functions for different predictive model types:\n",
    "\n",
    "- **Regression**: Mean Squared Error or ‘mse‘.\n",
    "- **Binary Classification (2 class)**: Logarithmic Loss, also called cross entropy or ‘binary_crossentropy‘.\n",
    "- **Multiclass Classification (>2 class)**: Multiclass Logarithmic Loss or ‘categorical_crossentropy‘."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Loss functions \n",
    "\n",
    "Some common ones that I've heard of :\n",
    "\n",
    "- mean_squared_error\n",
    "- mean_absolute_error\n",
    "- mean_absolute_percentage_error\n",
    "- mean_squared_logarithmic_error\n",
    "- logcosh\n",
    "- categorical_crossentropy\n",
    "- sparse_categorical_crossentropy\n",
    "- binary_crossentropy\n",
    "- cosine_proximity\n",
    "- poisson\n",
    "\n",
    "[All loss functions available here](https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Optimizers \n",
    "\n",
    "Some common ones I've seen being used : \n",
    "\n",
    "- SGD\n",
    "- RMSprop\n",
    "- Adam\n",
    "- Adagrad\n",
    "\n",
    "[All Optimizers mentioned here](https://keras.io/optimizers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different metrics\n",
    "\n",
    "Some common ones I've used : \n",
    "- \"accuracy\" (means binary_accuracy only)\n",
    "- binary_accuracy\n",
    "- categorical_accuracy\n",
    "\n",
    "[All metrics here](https://keras.io/metrics/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "Okay, now that we've defined layers and losses and optimizers for a model, we've basically defined the model completely. All that is left is to feed (fit) it some data and let it train!\n",
    "So, let's do that now. \n",
    "We will be using `fit` method for this purpose.\n",
    "\n",
    "Definition : `fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)`\n",
    "\n",
    "**Understanding the parameters**:\n",
    "    - x: Numpy array of training data.\n",
    "    - y: Numpy array of target (label) data. \n",
    "    - batch_size : Whatever mini-batch size to use. Default : 32. Possible values - any integer or None.\n",
    "    - epochs : no. of epochs to train for\n",
    "    - verbose : 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "    - callbacks : This is an amazing thing. I've talked about it below in another cell. \n",
    "    - validation_split: Float between 0 and 1. If you say give 0.3, then 30% of your training data would actually not be used for training set and instead be used for validation as a dev set. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n",
    "    - validation_data : If you have a separate validation set, then we can specify that as a tuple (x_devset,y_devset) here. Giving this would ignore validation_split\n",
    "    - shuffle : whether to shuffle the training data before each epoch (True/False). True by default.\n",
    "    - class_weight: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "    - sample_weight: Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only).\n",
    "    - initial_epoch: Epoch at which to start training (useful for resuming a previous training run).\n",
    "    - steps_per_epoch: Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined.\n",
    "    - validation_steps: Only relevant if steps_per_epoch is specified.\n",
    "\n",
    "Mostly, batch_size, epochs, verbose, callbacks, validation_split and validation_data seem to be important params here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (60000, 784)\n",
      "y_train shape :  (60000,)\n",
      "y_train_mod shape :  (60000, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hid1 (Dense)                 (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "hid2 (Dense)                 (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "hid3 (Dense)                 (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 81,285\n",
      "Trainable params: 81,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 5.8285 - acc: 0.6262 - val_loss: 3.0467 - val_acc: 0.7993\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 2.7797 - acc: 0.8180 - val_loss: 2.5202 - val_acc: 0.8358\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 2.4796 - acc: 0.8387 - val_loss: 2.5807 - val_acc: 0.8328\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 2.3522 - acc: 0.8481 - val_loss: 2.3529 - val_acc: 0.8492\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 2.2577 - acc: 0.8545 - val_loss: 2.2772 - val_acc: 0.8539\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 2.2864 - acc: 0.8529 - val_loss: 2.4151 - val_acc: 0.8441\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 2.2121 - acc: 0.8577 - val_loss: 2.3341 - val_acc: 0.8517\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 2.1222 - acc: 0.8642 - val_loss: 2.2117 - val_acc: 0.8592\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 2.1145 - acc: 0.8651 - val_loss: 2.1352 - val_acc: 0.8642\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 2.1089 - acc: 0.8654 - val_loss: 2.1911 - val_acc: 0.8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e799eb8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST using keras basic DNN model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# loading and fixing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"x_train shape : \",x_train_mod.shape)\n",
    "print(\"y_train shape : \",y_train.shape)\n",
    "x_train_mod = x_train.reshape(x_train.shape[0],784)\n",
    "y_train_mod = np_utils.to_categorical(y_train, 10)\n",
    "print(\"y_train_mod shape : \",y_train_mod.shape)\n",
    "\n",
    "# Define a simple model which take inputs Nonex28x28\n",
    "modelB = Sequential()\n",
    "modelB.add(Dense(100, input_dim=784, activation='relu', name='hid1'))\n",
    "modelB.add(Dense(25, activation='relu', name='hid2'))\n",
    "modelB.add(Dense(10, activation='softmax', name='hid3'))\n",
    "print(modelB.summary())\n",
    "\n",
    "# configure loss & optimizer\n",
    "modelB.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Feed data and train!\n",
    "modelB.fit(x_train_mod, y_train_mod, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks in training (fit)\n",
    "\n",
    "While using `fit` function, one of the parameters we can pass is callbacks, which accepts a list of `keras.callbacks.Callback` instances. These callbacks can help us log things at different epochs, save models at checkpoints, stop training if a metric isn't improving and many other useful things...\n",
    "\n",
    "Here are list of useful callbacks : \n",
    "    - TerminateOnNaN : Callback that terminates training when a NaN loss is encountered. Sometimes you've coded something incorrectly, and loss starts becoming NaN after a while. So, you should stop training then!\n",
    "    - ModelCheckpoint : Save the model after every epoch. [More Info here](https://keras.io/callbacks/#modelcheckpoint)\n",
    "    - EarlyStopping : Stop training when a monitored quantity has stopped improving. It'll stop if val_acc for example stops improving. [Read here](https://keras.io/callbacks/#earlystopping)\n",
    "    - RemoteMonitor : stream your logs to a server by making POST calls\n",
    "    - TensorBoard : This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model.\n",
    "    - ReduceLROnPlateau : Reduce learning rate when a metric has stopped improving.\n",
    "    - LambdaCallback : Callback for creating simple, custom callbacks on-the-fly. [More info](https://keras.io/callbacks/#lambdacallback)\n",
    "                                                                                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating your model\n",
    "\n",
    "Now's the time to check how your model performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 47us/step\n",
      "loss: 2.17363247015  | accuracy: 0.8622\n",
      "prediction for 0th test data example: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# fix the test data as well\n",
    "x_test_mod = x_test.reshape(x_test.shape[0],784)\n",
    "y_test_mod = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# evaluate it\n",
    "loss, accuracy = modelB.evaluate(x_test_mod, y_test_mod)\n",
    "print(\"loss:\",loss,\" | accuracy:\",accuracy)\n",
    "\n",
    "# predictions for the dataset (if I wish to check predictions myself)\n",
    "predictions = modelB.predict(x_test_mod)\n",
    "print(\"prediction for 0th test data example:\",predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly, [Here's some more great methods](https://keras.io/models/sequential/) to be used with a Sequential model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice : CNN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
